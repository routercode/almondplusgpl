diff -Naur linux-2.6.36/arch/arm/boot/compressed/Makefile linux-2.6.36-new/arch/arm/boot/compressed/Makefile
--- linux-2.6.36/arch/arm/boot/compressed/Makefile	2010-10-20 13:30:22.000000000 -0700
+++ linux-2.6.36-new/arch/arm/boot/compressed/Makefile	2011-09-04 11:08:18.000000000 -0700
@@ -37,6 +37,10 @@
 OBJS		+= head-sharpsl.o
 endif
 
+ifeq ($(CONFIG_ARCH_GOLDENGATE),y)
+OBJS		+= head-goldengate.o
+endif
+
 ifeq ($(CONFIG_CPU_ENDIAN_BE32),y)
 ifeq ($(CONFIG_CPU_CP15),y)
 OBJS		+= big-endian.o
diff -Naur linux-2.6.36/arch/arm/boot/compressed/head.S linux-2.6.36-new/arch/arm/boot/compressed/head.S
--- linux-2.6.36/arch/arm/boot/compressed/head.S	2011-09-04 09:47:11.000000000 -0700
+++ linux-2.6.36-new/arch/arm/boot/compressed/head.S	2011-09-04 11:08:18.000000000 -0700
@@ -477,24 +477,106 @@
 #endif
 		mov	pc, r12
 
+/*
+ *	v7_flush_dcache_all()
+ *
+ *	Flush the whole D-cache.
+ *
+ *	Corrupted registers: r0-r7, r9-r11 (r6 only in Thumb mode)
+ *
+ *	- mm    - mm_struct describing address space
+ */
+ENTRY(v7_flush_dcache_all)
+	dmb					@ ensure ordering with previous memory accesses
+	mrc	p15, 1, r0, c0, c0, 1		@ read clidr
+	ands	r3, r0, #0x7000000		@ extract loc from clidr
+	mov	r3, r3, lsr #23			@ left align loc bit field
+	beq	finish			@ if loc is 0, then no need to clean
+	mov	r10, #0				@ start clean at cache level 0
+looop1:
+	add	r2, r10, r10, lsr #1		@ work out 3x current cache level
+	mov	r1, r0, lsr r2			@ extract cache type bits from clidr
+	and	r1, r1, #7			@ mask of the bits for current cache only
+	cmp	r1, #2				@ see what cache we have at this level
+	blt	skipp				@ skip if no cache, or just i-cache
+	mcr	p15, 2, r10, c0, c0, 0		@ select current cache level in cssr
+	isb					@ isb to sych the new cssr&csidr
+	mrc	p15, 1, r1, c0, c0, 0		@ read the new csidr
+	and	r2, r1, #7			@ extract the length of the cache lines
+	add	r2, r2, #4			@ add 4 (line length offset)
+	ldr	r4, =0x3ff
+	ands	r4, r4, r1, lsr #3		@ find maximum number on the way size
+	clz	r5, r4				@ find bit position of way size increment
+	ldr	r7, =0x7fff
+	ands	r7, r7, r1, lsr #13		@ extract max number of the index size
+looop2:
+	mov	r9, r4				@ create working copy of max way size
+looop3:
+ ARM(	orr	r11, r10, r9, lsl r5	)	@ factor way and cache number into r11
+ THUMB(	lsl	r6, r9, r5		)
+ THUMB(	orr	r11, r10, r6		)	@ factor way and cache number into r11
+ ARM(	orr	r11, r11, r7, lsl r2	)	@ factor index number into r11
+ THUMB(	lsl	r6, r7, r2		)
+ THUMB(	orr	r11, r11, r6		)	@ factor index number into r11
+//	mcr	p15, 0, r11, c7, c14, 2		@ clean & invalidate by set/way
+	mcr	p15, 0, r11, c7, c6, 2		@ invalidate by set/way, Jason
+	subs	r9, r9, #1			@ decrement the way
+	bge	looop3
+	subs	r7, r7, #1			@ decrement the index
+	bge	looop2
+skipp:
+	add	r10, r10, #2			@ increment cache number
+	cmp	r3, r10
+	bgt	looop1
+finish:
+	mov	r10, #0				@ swith back to cache level 0
+	mcr p15, 0, r10, c7, c5, 0		@ invalidate whole I-Cache, Jason
+	mcr	p15, 2, r10, c0, c0, 0		@ select current cache level in cssr
+	dsb
+	isb
+	mov	pc, lr
+ENDPROC(v7_flush_dcache_all)
+
 __armv7_mmu_cache_on:
 		mov	r12, lr
 #ifdef CONFIG_MMU
 		mrc	p15, 0, r11, c0, c1, 4	@ read ID_MMFR0
 		tst	r11, #0xf		@ VMSA
+		it	ne				@ Jason, for thumb/ARM portbility
 		blne	__setup_mmu
+
+		/* Invalidate D-cache all, Jason */
+		ldr	r0, =0xF6400000
+		/* mov r0, #0xF6400000 */
+		orr r0, r0, #0x1000
+		stmia  r0!, {r1-r12}
+		bl	v7_flush_dcache_all
+		/* mov r0, #0xF6400000 */
+		ldr	r0, =0xF6400000
+		orr r0, r0, #0x1000
+		ldmia  r0!, {r1-r12}
+		/* Invalidate D-cache all, Jason */
+
 		mov	r0, #0
 		mcr	p15, 0, r0, c7, c10, 4	@ drain write buffer
 		tst	r11, #0xf		@ VMSA
+		it	ne				@ Jason, for thumb/ARM portbility
 		mcrne	p15, 0, r0, c8, c7, 0	@ flush I,D TLBs
 #endif
 		mrc	p15, 0, r0, c1, c0, 0	@ read control reg
 		orr	r0, r0, #0x5000		@ I-cache enable, RR cache replacement
-		orr	r0, r0, #0x003c		@ write buffer
+#ifndef CONFIG_CPU_DCACHE_DISABLE
+		orr	r0, r0, #0x003C		@ D-cache enable
+#endif
+#ifdef CONFIG_CPU_ICACHE_DISABLE
+		bic	r0, r0, #0x1000
+#endif
+
 #ifdef CONFIG_MMU
 #ifdef CONFIG_CPU_ENDIAN_BE8
 		orr	r0, r0, #1 << 25	@ big-endian page tables
 #endif
+		itttt	ne				@ Jason, for thumb/ARM portbility
 		orrne	r0, r0, #1		@ MMU enabled
 		movne	r1, #-1
 		mcrne	p15, 0, r3, c2, c0, 0	@ load page table pointer
@@ -604,10 +686,15 @@
 #else
 		ldr	r9, =CONFIG_PROCESSOR_ID
 #endif
-1:		ldr	r1, [r12, #0]		@ get value
-		ldr	r2, [r12, #4]		@ get mask
-		eor	r1, r1, r9		@ (real ^ match)
-		tst	r1, r2			@       & mask
+//1:		ldr	r1, [r12, #0]		@ get value
+//		ldr	r2, [r12, #4]		@ get mask
+//		eor	r1, r1, r6		@ (real ^ match)
+//		tst	r1, r2			@       & mask
+1:		ldr	r2, [r12, #4]		@ get mask	@ Jason
+		ldr	r1, [r12, #0]		@ get value
+		and	r2, r9, r2		@ keep the relevant bits Suresh r9 has processorid 
+		teq	r1, r2			@ match with the value
+		itt	eq
  ARM(		addeq	pc, r12, r3		) @ call cache function
  THUMB(		addeq	r12, r3			)
  THUMB(		moveq	pc, r12			) @ call cache function
